{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET DEEP LEARNING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTATION DES MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-TRAITEMENT DES DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training damage images:  5000\n",
      "total validation damage images:  1000\n",
      "total test damage images:  8000\n",
      "total training no damage images:  5000\n",
      "total validation no damage images:  1000\n",
      "total test no damage images:  1000\n"
     ]
    }
   ],
   "source": [
    "print('total training damage images: ',len(os.listdir(\"./train_another/damage\")))\n",
    "print('total validation damage images: ',len(os.listdir(\"./validation_another/damage\")))\n",
    "print('total test damage images: ',len(os.listdir(\"./test_another/damage\")))\n",
    "print('total training no damage images: ',len(os.listdir(\"./train_another/no_damage\")))\n",
    "print('total validation no damage images: ',len(os.listdir(\"./validation_another/no_damage\")))\n",
    "print('total test no damage images: ',len(os.listdir(\"./test_another/no_damage\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des images en séparant en jeu train / test / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((150,150)),\n",
    "                                 transforms.ToTensor()])\n",
    "batch_size = 20\n",
    "\n",
    "df_train = datasets.ImageFolder(\"./train_another\",transform=transform)\n",
    "train_dataloader = DataLoader(dataset=df_train, batch_size=batch_size, shuffle=True, num_workers = 4 , pin_memory = True)\n",
    "\n",
    "df_test = datasets.ImageFolder(\"./test_another\",transform=transform)\n",
    "test_dataloader = DataLoader(dataset=df_test, batch_size=batch_size, shuffle=True,num_workers = 4 , pin_memory = True)\n",
    "\n",
    "df_validation = datasets.ImageFolder(\"./validation_another\",transform=transform)\n",
    "validation_dataloader = DataLoader(dataset=df_validation, batch_size=batch_size, shuffle=True,num_workers = 4 , pin_memory = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons de visualiser les classes de nos images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['damage', 'no_damage']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELISATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELE 1 : Reproduction du modèle de CAO & CHOE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création de la classe qui va nous permettre de faire notre classification d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création de la classe qui va permettre de créer notre premier modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HurricaneClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3,32, kernel_size = (3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32,64, kernel_size = (3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size = (3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(128,128, kernel_size = (3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(6272, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création des fonctions qui vont permettre d'évaluer notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    nb_etape = 0\n",
    "    outputs = []\n",
    "    for batch in val_loader:\n",
    "        nb_etape = nb_etape + 1\n",
    "        outputs.append(model.validation_step(batch))\n",
    "        if nb_etape == 50:\n",
    "            break\n",
    "            \n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        nb_etape = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            nb_etape = nb_etape+1\n",
    "            if nb_etape == 100:\n",
    "                break\n",
    "                \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history, train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour calculer la précision sur le jeu de données validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_CNN(net, valLoader):\n",
    "    correct, total = 0, 0\n",
    "    predictions = []\n",
    "    net.eval()\n",
    "    for i, data in enumerate(valLoader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)    \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.append(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.6821, val_loss: 0.6515, val_acc: 0.5650\n",
      "Epoch [1], train_loss: 0.6334, val_loss: 0.5907, val_acc: 0.8250\n",
      "Epoch [2], train_loss: 0.5575, val_loss: 0.6227, val_acc: 0.7550\n",
      "Epoch [3], train_loss: 0.5333, val_loss: 0.5010, val_acc: 0.8580\n",
      "Epoch [4], train_loss: 0.5103, val_loss: 0.4826, val_acc: 0.8700\n",
      "Epoch [5], train_loss: 0.5146, val_loss: 0.5591, val_acc: 0.8220\n",
      "Epoch [6], train_loss: 0.4572, val_loss: 0.4724, val_acc: 0.8850\n",
      "Epoch [7], train_loss: 0.4917, val_loss: 0.4612, val_acc: 0.8740\n",
      "Epoch [8], train_loss: 0.4732, val_loss: 0.4577, val_acc: 0.8810\n",
      "Epoch [9], train_loss: 0.4659, val_loss: 0.4786, val_acc: 0.8850\n",
      "Epoch [10], train_loss: 0.4610, val_loss: 0.4379, val_acc: 0.9030\n",
      "Epoch [11], train_loss: 0.4699, val_loss: 0.4426, val_acc: 0.8940\n",
      "Epoch [12], train_loss: 0.4499, val_loss: 0.4408, val_acc: 0.8970\n",
      "Epoch [13], train_loss: 0.4513, val_loss: 0.4420, val_acc: 0.9070\n",
      "Epoch [14], train_loss: 0.4375, val_loss: 0.4525, val_acc: 0.9000\n",
      "Epoch [15], train_loss: 0.4500, val_loss: 0.4490, val_acc: 0.8940\n",
      "Epoch [16], train_loss: 0.4485, val_loss: 0.4280, val_acc: 0.9120\n",
      "Epoch [17], train_loss: 0.4451, val_loss: 0.4436, val_acc: 0.9020\n",
      "Epoch [18], train_loss: 0.4432, val_loss: 0.4334, val_acc: 0.9130\n",
      "Epoch [19], train_loss: 0.4422, val_loss: 0.4435, val_acc: 0.9140\n",
      "Epoch [20], train_loss: 0.4365, val_loss: 0.4346, val_acc: 0.9180\n",
      "Epoch [21], train_loss: 0.4245, val_loss: 0.4473, val_acc: 0.9020\n",
      "Epoch [22], train_loss: 0.4319, val_loss: 0.4240, val_acc: 0.9120\n",
      "Epoch [23], train_loss: 0.4206, val_loss: 0.4389, val_acc: 0.9080\n",
      "Epoch [24], train_loss: 0.4439, val_loss: 0.4293, val_acc: 0.9140\n",
      "Epoch [25], train_loss: 0.4335, val_loss: 0.4695, val_acc: 0.8720\n",
      "Epoch [26], train_loss: 0.4281, val_loss: 0.4080, val_acc: 0.9220\n",
      "Epoch [27], train_loss: 0.4113, val_loss: 0.4267, val_acc: 0.9120\n",
      "Epoch [28], train_loss: 0.4259, val_loss: 0.4171, val_acc: 0.9150\n",
      "Epoch [29], train_loss: 0.4174, val_loss: 0.4384, val_acc: 0.9130\n",
      "Epoch [30], train_loss: 0.4213, val_loss: 0.4381, val_acc: 0.9010\n",
      "Epoch [31], train_loss: 0.4160, val_loss: 0.4349, val_acc: 0.9130\n",
      "Epoch [32], train_loss: 0.4115, val_loss: 0.4272, val_acc: 0.9190\n",
      "Epoch [33], train_loss: 0.4186, val_loss: 0.4093, val_acc: 0.9290\n",
      "Epoch [34], train_loss: 0.4273, val_loss: 0.4328, val_acc: 0.9230\n",
      "Epoch [35], train_loss: 0.4396, val_loss: 0.4241, val_acc: 0.9250\n",
      "Epoch [36], train_loss: 0.4346, val_loss: 0.4133, val_acc: 0.9230\n",
      "Epoch [37], train_loss: 0.4246, val_loss: 0.4083, val_acc: 0.9300\n",
      "Epoch [38], train_loss: 0.4132, val_loss: 0.4024, val_acc: 0.9310\n",
      "Epoch [39], train_loss: 0.4140, val_loss: 0.4195, val_acc: 0.9210\n",
      "Epoch [40], train_loss: 0.4198, val_loss: 0.4033, val_acc: 0.9360\n",
      "Epoch [41], train_loss: 0.4118, val_loss: 0.4677, val_acc: 0.8990\n",
      "Epoch [42], train_loss: 0.4263, val_loss: 0.4129, val_acc: 0.9190\n",
      "Epoch [43], train_loss: 0.4147, val_loss: 0.4187, val_acc: 0.9250\n",
      "Epoch [44], train_loss: 0.4000, val_loss: 0.4198, val_acc: 0.9200\n",
      "Epoch [45], train_loss: 0.4295, val_loss: 0.4073, val_acc: 0.9240\n",
      "Epoch [46], train_loss: 0.4060, val_loss: 0.4131, val_acc: 0.9320\n",
      "Epoch [47], train_loss: 0.4052, val_loss: 0.4100, val_acc: 0.9140\n",
      "Epoch [48], train_loss: 0.4039, val_loss: 0.4251, val_acc: 0.9210\n",
      "Epoch [49], train_loss: 0.4144, val_loss: 0.4011, val_acc: 0.9320\n"
     ]
    }
   ],
   "source": [
    "model = HurricaneClassification()\n",
    "num_epochs = 50\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 1e-4\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history, loss = fit(num_epochs, lr, model, train_dataloader, validation_dataloader, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 148, 148]             896\n",
      "              ReLU-2         [-1, 32, 148, 148]               0\n",
      "         MaxPool2d-3           [-1, 32, 74, 74]               0\n",
      "            Conv2d-4           [-1, 64, 72, 72]          18,496\n",
      "              ReLU-5           [-1, 64, 72, 72]               0\n",
      "         MaxPool2d-6           [-1, 64, 36, 36]               0\n",
      "            Conv2d-7          [-1, 128, 34, 34]          73,856\n",
      "              ReLU-8          [-1, 128, 34, 34]               0\n",
      "         MaxPool2d-9          [-1, 128, 17, 17]               0\n",
      "           Conv2d-10          [-1, 128, 15, 15]         147,584\n",
      "             ReLU-11          [-1, 128, 15, 15]               0\n",
      "        MaxPool2d-12            [-1, 128, 7, 7]               0\n",
      "          Flatten-13                 [-1, 6272]               0\n",
      "          Dropout-14                 [-1, 6272]               0\n",
      "           Linear-15                  [-1, 512]       3,211,776\n",
      "             ReLU-16                  [-1, 512]               0\n",
      "           Linear-17                    [-1, 2]           1,026\n",
      "             ReLU-18                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 3,453,634\n",
      "Trainable params: 3,453,634\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 20.86\n",
      "Params size (MB): 13.17\n",
      "Estimated Total Size (MB): 34.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(3, 150, 150))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée également un sauvegarde de la variable loss pour éviter de la recharger en cas de crash à cause de matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# sauvegarde\n",
    "with open(\"loss1\",\"wb\") as f:\n",
    "    pickle.dump(loss,f)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement\n",
    "with open(\"loss1\",\"rb\") as f:\n",
    "    loss_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code pour l'affichage du plot est en commentaire car il arrive que matplotlib tue notre kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.4509, requires_grad=True), tensor(0.3548, requires_grad=True), tensor(0.5223, requires_grad=True), tensor(0.4511, requires_grad=True), tensor(0.3464, requires_grad=True), tensor(0.2550, requires_grad=True), tensor(0.5251, requires_grad=True), tensor(0.3134, requires_grad=True), tensor(0.3033, requires_grad=True), tensor(0.3829, requires_grad=True), tensor(0.3678, requires_grad=True), tensor(0.4022, requires_grad=True), tensor(0.2800, requires_grad=True), tensor(0.4875, requires_grad=True), tensor(0.2494, requires_grad=True), tensor(0.3815, requires_grad=True), tensor(0.4023, requires_grad=True), tensor(0.4261, requires_grad=True), tensor(0.3152, requires_grad=True), tensor(0.3257, requires_grad=True), tensor(0.6313, requires_grad=True), tensor(0.3922, requires_grad=True), tensor(0.3583, requires_grad=True), tensor(0.3142, requires_grad=True), tensor(0.5271, requires_grad=True), tensor(0.4069, requires_grad=True), tensor(0.3888, requires_grad=True), tensor(0.4729, requires_grad=True), tensor(0.2824, requires_grad=True), tensor(0.4586, requires_grad=True), tensor(0.4186, requires_grad=True), tensor(0.3631, requires_grad=True), tensor(0.4243, requires_grad=True), tensor(0.4224, requires_grad=True), tensor(0.3150, requires_grad=True), tensor(0.5640, requires_grad=True), tensor(0.3672, requires_grad=True), tensor(0.3576, requires_grad=True), tensor(0.4285, requires_grad=True), tensor(0.4775, requires_grad=True), tensor(0.5302, requires_grad=True), tensor(0.5245, requires_grad=True), tensor(0.4959, requires_grad=True), tensor(0.3422, requires_grad=True), tensor(0.3491, requires_grad=True), tensor(0.3833, requires_grad=True), tensor(0.4774, requires_grad=True), tensor(0.3839, requires_grad=True), tensor(0.5069, requires_grad=True), tensor(0.5006, requires_grad=True), tensor(0.3449, requires_grad=True), tensor(0.4321, requires_grad=True), tensor(0.4280, requires_grad=True), tensor(0.6287, requires_grad=True), tensor(0.4892, requires_grad=True), tensor(0.3467, requires_grad=True), tensor(0.4687, requires_grad=True), tensor(0.5023, requires_grad=True), tensor(0.3818, requires_grad=True), tensor(0.4588, requires_grad=True), tensor(0.1887, requires_grad=True), tensor(0.3149, requires_grad=True), tensor(0.5536, requires_grad=True), tensor(0.1863, requires_grad=True), tensor(0.4562, requires_grad=True), tensor(0.5617, requires_grad=True), tensor(0.4509, requires_grad=True), tensor(0.4652, requires_grad=True), tensor(0.2407, requires_grad=True), tensor(0.3277, requires_grad=True), tensor(0.4941, requires_grad=True), tensor(0.5382, requires_grad=True), tensor(0.4812, requires_grad=True), tensor(0.3993, requires_grad=True), tensor(0.4297, requires_grad=True), tensor(0.3530, requires_grad=True), tensor(0.3818, requires_grad=True), tensor(0.4855, requires_grad=True), tensor(0.3888, requires_grad=True), tensor(0.4823, requires_grad=True), tensor(0.4433, requires_grad=True), tensor(0.3258, requires_grad=True), tensor(0.3586, requires_grad=True), tensor(0.4195, requires_grad=True), tensor(0.2789, requires_grad=True), tensor(0.3156, requires_grad=True), tensor(0.3803, requires_grad=True), tensor(0.3502, requires_grad=True), tensor(0.5491, requires_grad=True), tensor(0.3860, requires_grad=True), tensor(0.4214, requires_grad=True), tensor(0.3547, requires_grad=True), tensor(0.5208, requires_grad=True), tensor(0.4168, requires_grad=True), tensor(0.6343, requires_grad=True), tensor(0.2705, requires_grad=True), tensor(0.5661, requires_grad=True), tensor(0.3561, requires_grad=True), tensor(0.4658, requires_grad=True), tensor(0.5564, requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "loss_tensor = torch.stack(loss_loaded)\n",
    "loss_np=torch.detach(loss_tensor).numpy()\n",
    "\n",
    "#plt.plot(loss)\n",
    "#plt.xlabel('Itération')\n",
    "#plt.ylabel('Perte')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network on the validation images is: 92 %\n"
     ]
    }
   ],
   "source": [
    "val_model1 = acc_val(model,validation_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELE 2 : Fine tuning VGG-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spica\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\spica\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model2 = torchvision.models.vgg19(pretrained=True)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   101] loss: 0.561\n",
      "[2,   101] loss: 0.459\n",
      "[3,   101] loss: 0.430\n",
      "[4,   101] loss: 0.278\n",
      "[5,   101] loss: 0.406\n",
      "[6,   101] loss: 0.122\n",
      "[7,   101] loss: 0.421\n",
      "[8,   101] loss: 0.447\n",
      "[9,   101] loss: 0.280\n",
      "[10,   101] loss: 0.244\n",
      "[11,   101] loss: 0.341\n",
      "[12,   101] loss: 0.464\n",
      "[13,   101] loss: 0.166\n",
      "[14,   101] loss: 0.304\n",
      "[15,   101] loss: 0.228\n",
      "[16,   101] loss: 0.271\n",
      "[17,   101] loss: 0.373\n",
      "[18,   101] loss: 0.301\n",
      "[19,   101] loss: 0.225\n",
      "[20,   101] loss: 0.398\n"
     ]
    }
   ],
   "source": [
    "num_classes = 1000\n",
    "\n",
    "# Verrouillage des couches du modèle (sauf la dernière) pour éviter leur mise à jour lors de l'entraînement\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modification du nombre de classes en sortie (par défaut 1000) si nécessaire\n",
    "model2.classifier[6] = torch.nn.Linear(in_features=4096, out_features=num_classes)\n",
    "\n",
    "# Déverrouillage de la dernière couche pour permettre son entraînement\n",
    "for param in model2.classifier[6].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Conversion en mode \"entraînement\"\n",
    "model2.train()\n",
    "\n",
    "# Préparation des transformateurs pour les données d'entraînement\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='./train_another', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "loss_values = []\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Chargement des entrées et des étiquettes\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Calcul des sorties à l'aide de la méthode forward\n",
    "        outputs = model2(inputs)\n",
    "        \n",
    "        # Calcul de la perte\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Ajout de la perte à la liste\n",
    "        loss_values.append(loss.item())\n",
    "        # Calcul des gradients pour la rétropropagation\n",
    "        optimizer = torch.optim.SGD(model2.classifier[6].parameters(), lr=0.001, momentum=0.9)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Mise à jour des paramètres du modèle\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Affichage de la progression de l'entraînement toutes les 100 itérations\n",
    "        if i ==100:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, loss.item()))\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sauvegarde le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(),\"model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# sauvegarde\n",
    "with open(\"loss_vgg19\", \"wb\") as f:\n",
    "    pickle.dump(loss_values, f)\n",
    "    \n",
    "# chargement\n",
    "with open(\"loss_vgg19\", \"rb\") as f:\n",
    "    loss2_loaded = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbe de gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss2_loaded)\n",
    "plt.xlabel('Itération')\n",
    "plt.ylabel('Perte')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 50 %\n"
     ]
    }
   ],
   "source": [
    "val_model2 = val_CNN(model2,validation_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 3 : Création de notre propre CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotreModeleClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3,32, kernel_size = (3,3)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32,64, kernel_size = (3,3)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size = (3,3)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(128,128, kernel_size = (3,3)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128*7*7, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELES DE MACHINE LEARNING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction des features du modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataloader, model, n_sample, n_features):\n",
    "    features = np.zeros(shape=(n_sample,n_features))\n",
    "    batchSize = dataloader.batch_size\n",
    "    labels = np.zeros(shape = (n_sample))\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in dataloader:\n",
    "        model.eval()\n",
    "        features_batch = model(inputs_batch).detach().numpy()\n",
    "        features[i * batchSize: (i + 1) * batchSize] = features_batch\n",
    "        labels[i * batchSize: (i + 1) * batchSize] = labels_batch\n",
    "        i += 1\n",
    "        if i * batchSize >= n_sample:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde les outputs de notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3,150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = extract_features(train_dataloader,model,10000,2)\n",
    "x_test, y_test = extract_features(validation_dataloader, model, 2000, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = \"\"\n",
    "best_acc = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle 1 : Arbres de décisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[875 125]\n",
      " [150 850]]\n",
      "Précision : 0.8625\n",
      "DecisionTreeClassifier()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix \n",
    "y_pred = clf.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Précision : \" + str(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "if accuracy_score(y_test,y_pred)>best_acc:\n",
    "    best_model = clf\n",
    "    best_acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle 2 : Fôrets aléatoires + GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=11, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=11, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=12, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=13, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=13, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=13, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=13, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=13, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=13, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=13, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=14, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=2, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=14, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=14, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=14, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=14, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=14, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=14, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=14, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=15, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=15, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=15, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=15, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=15, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=15, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=16, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=16, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=16, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=16, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=16, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=16, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=17, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=17, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=17, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=18, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=18, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=18, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=18, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=19, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=19, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=19, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=19, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=19, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3; total time=   0.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3; total time=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]),\n",
       "                         'min_samples_leaf': array([2, 3]),\n",
       "                         'min_samples_split': array([2, 3])},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'max_depth' : np.arange(start = 10, stop = 21, step = 1) , \n",
    "              'min_samples_leaf' : np.arange(start = 2, stop = 4, step = 1),\n",
    "              'min_samples_split' : np.arange(start = 2, stop = 4, step = 1)}\n",
    "\n",
    "clf2 = RandomForestClassifier()\n",
    "clf2 = GridSearchCV(clf2,parameters,scoring=\"accuracy\",verbose=2,cv=5)\n",
    "clf2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[934  66]\n",
      " [117 883]]\n",
      "Précision : 0.9085\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf2.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Précision : \" + str(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "if accuracy_score(y_test,y_pred)>best_acc:\n",
    "    best_model = clf2\n",
    "    best_acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèles 3 : AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf3 = AdaBoostClassifier()\n",
    "clf3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[932  68]\n",
      " [120 880]]\n",
      "Précision : 0.906\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf3.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Précision : \" + str(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "if accuracy_score(y_test,y_pred)>best_acc:\n",
    "    best_model = clf3\n",
    "    best_acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle 4 : Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "clf4 = lgb.LGBMClassifier()\n",
    "clf4.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[928  72]\n",
      " [112 888]]\n",
      "Précision : 0.908\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf4.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Précision : \" + str(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "if accuracy_score(y_test,y_pred)>best_acc:\n",
    "    best_model = clf4\n",
    "    best_acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle 5 : Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf5 = BaggingClassifier()\n",
    "clf5.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[914  86]\n",
      " [142 858]]\n",
      "Précision : 0.886\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf5.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Précision : \" + str(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "if accuracy_score(y_test,y_pred)>best_acc:\n",
    "    best_model = clf5\n",
    "    best_acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
      "             param_grid={'max_depth': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]),\n",
      "                         'min_samples_leaf': array([2, 3]),\n",
      "                         'min_samples_split': array([2, 3])},\n",
      "             scoring='accuracy', verbose=2)\n"
     ]
    }
   ],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre meilleur modèle est :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notre meilleur modèle est : GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
      "             param_grid={'max_depth': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]),\n",
      "                         'min_samples_leaf': array([2, 3]),\n",
      "                         'min_samples_split': array([2, 3])},\n",
      "             scoring='accuracy', verbose=2)\n",
      "avec une précision de 0.9085\n"
     ]
    }
   ],
   "source": [
    "print(\"Notre meilleur modèle est : \"+str(best_model))\n",
    "print(\"avec une précision de \"+ str(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
